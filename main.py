#!/usr/bin/env python3
"""
FIXED: Revolutionary Multi-Agent Voice AI System - RunPod Optimized
Fixed external URL detection and ChromaDB integration for RunPod deployment.
"""
import os
import sys
import asyncio
import logging
import json
import time
import threading
import subprocess
import signal
import base64
import re
import requests
from typing import Dict, Any, Optional, List
from contextlib import asynccontextmanager
import uuid
from pathlib import Path
import yaml
from collections import defaultdict

# FastAPI imports with enhanced performance
from fastapi import FastAPI, Request, Response, WebSocket, WebSocketDisconnect, BackgroundTasks, HTTPException, Depends, Form
from fastapi.responses import JSONResponse, PlainTextResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
import uvicorn
from pydantic import BaseModel

# Twilio integration
from twilio.twiml.voice_response import VoiceResponse, Connect, Stream, Say, Gather, Record
from dotenv import load_dotenv

# Core system imports
from app.core.agent_orchestrator import EnhancedMultiAgentOrchestrator as MultiAgentOrchestrator
from app.core.state_manager import ConversationStateManager
from app.core.health_monitor import SystemHealthMonitor

# Agent and vector systems
from app.agents.registry import AgentRegistry  
from app.agents.router import IntelligentAgentRouter
from app.agents.llm_router import LLMIntelligentRouter  # NEW: LLM-based router
from app.vector_db.hybrid_vector_system import HybridVectorSystem

# Voice processing with enhanced pipeline
from app.voice.enhanced_stt import EnhancedSTTSystem
from app.voice.dual_streaming_tts import DualStreamingTTSEngine, StreamingMode, create_voice_params_for_agent
from app.telephony.advanced_websocket_handler import AdvancedWebSocketHandler

# Tool orchestration
from app.tools.tool_orchestrator import ComprehensiveToolOrchestrator

from app.llm.context_manager import LLMContextManager, ContextType
from app.llm.intelligent_router import IntelligentLLMRouter, RoutingStrategy  
from app.llm.streaming_handler import LLMStreamingHandler, StreamingConfig

# Load environment variables
load_dotenv()

# PERMANENT FIX: Detect correct working directory and config paths
def get_project_root():
    """Automatically detect the project root directory."""
    current_dir = Path.cwd()
    
    # Check if we're already in the right directory (has main.py and app/)
    if (current_dir / "main.py").exists() and (current_dir / "app").exists():
        return current_dir
    
    # Check common locations
    possible_roots = [
        Path("/workspace/Google-STT-Google-TTS"),
        Path("/workspace"),
        current_dir,
        current_dir.parent,
    ]
    
    for root in possible_roots:
        if (root / "main.py").exists() and (root / "app").exists():
            return root
    
    # Fallback to current directory
    return current_dir

# ENHANCED: RunPod URL Detection
def detect_runpod_url():
    """
    Detect RunPod external URL automatically.
    Fixed version that properly detects the RunPod proxy URL.
    """
    # First, check environment variables
    base_url = os.getenv('BASE_URL')
    if base_url:
        print(f"‚úÖ Using BASE_URL from environment: {base_url}")
        return base_url
    
    # Check for RunPod specific environment variables
    runpod_pod_id = os.getenv('RUNPOD_POD_ID')
    runpod_tcp_port_5000 = os.getenv('RUNPOD_TCP_PORT_5000')
    runpod_public_ip = os.getenv('RUNPOD_PUBLIC_IP')
    
    if runpod_tcp_port_5000:
        # RunPod provides the external URL directly
        runpod_url = f"https://{runpod_tcp_port_5000}"
        print(f"‚úÖ Detected RunPod URL from RUNPOD_TCP_PORT_5000: {runpod_url}")
        return runpod_url
    
    if runpod_pod_id:
        # Try to construct RunPod URL using pod ID
        potential_urls = [
            f"https://{runpod_pod_id}-5000.proxy.runpod.net",
            f"https://{runpod_pod_id}-tcp-5000.proxy.runpod.net",
        ]
        
        for url in potential_urls:
            try:
                response = requests.get(f"{url}/health", timeout=5)
                if response.status_code in [200, 404]:  # 404 is OK, means server is running but route not found
                    print(f"‚úÖ Detected RunPod URL: {url}")
                    return url
            except:
                continue
    
    # Try to detect from system hostname or metadata
    try:
        # Check common RunPod patterns
        hostname = os.uname().nodename
        if 'runpod' in hostname.lower():
            print(f"üîç RunPod hostname detected: {hostname}")
            
            # Try to get external URL from RunPod metadata service
            try:
                # This is a common pattern for RunPod
                metadata_response = requests.get('http://metadata.google.internal/computeMetadata/v1/instance/attributes/external-ip', 
                                              headers={'Metadata-Flavor': 'Google'}, timeout=5)
                if metadata_response.status_code == 200:
                    external_ip = metadata_response.text.strip()
                    runpod_url = f"https://{external_ip}:5000"
                    print(f"‚úÖ Detected RunPod URL from metadata: {runpod_url}")
                    return runpod_url
            except:
                pass
    except:
        pass
    
    # If we're in a container, check for common port mappings
    try:
        # Check if port 5000 is exposed
        with open('/proc/net/tcp', 'r') as f:
            for line in f:
                if ':1388' in line:  # 5000 in hex is 1388
                    print("üîç Port 5000 detected in container")
                    break
    except:
        pass
    
    # Default fallback for RunPod
    if runpod_pod_id or os.getenv('RUNPOD_PUBLIC_IP'):
        fallback_url = "https://your-runpod-url-here.proxy.runpod.net"
        print(f"‚ö†Ô∏è Could not auto-detect RunPod URL. Please set BASE_URL environment variable.")
        print(f"    Your RunPod URL should look like: https://xxxxx-5000.proxy.runpod.net")
        return fallback_url
    
    # Local development fallback
    return "http://localhost:5000"

# Set project root and change working directory
PROJECT_ROOT = get_project_root()
os.chdir(PROJECT_ROOT)
print(f"üîß Project root detected: {PROJECT_ROOT}")
print(f"üîÑ Working directory set to: {os.getcwd()}")

# Enhanced RunPod URL detection
BASE_URL = detect_runpod_url()

# Ensure logs directory exists and configure logging
try:
    os.makedirs('./logs', exist_ok=True)
    log_handlers = [
        logging.StreamHandler(),
        logging.FileHandler('./logs/voice_ai_system.log')
    ]
except (OSError, PermissionError) as e:
    print(f"Warning: Could not create log file: {e}")
    log_handlers = [logging.StreamHandler()]

# Configure enhanced logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
    handlers=log_handlers
)
logger = logging.getLogger(__name__)

# Suppress noisy logs
logging.getLogger('google.cloud').setLevel(logging.WARNING)
logging.getLogger('grpc').setLevel(logging.WARNING)
logging.getLogger('asyncio').setLevel(logging.WARNING)

# ============================================================================
# ENHANCED SERVICE MANAGER FOR RUNPOD DEPLOYMENT
# ============================================================================

class EnhancedServiceManager:
    """Enhanced service manager optimized for RunPod environment."""
    
    def __init__(self):
        self.redis_running = False
        self.startup_attempts = {}
        self.max_attempts = 3
        
    async def ensure_redis_running(self) -> bool:
        """Enhanced Redis startup for RunPod environment."""
        logger.info("üîß Ensuring Redis is running on RunPod...")
        
        # Test if Redis is already running
        if await self._test_redis_connection():
            logger.info("‚úÖ Redis already running")
            self.redis_running = True
            return True
        
        # RunPod-specific Redis startup commands
        runpod_redis_commands = [
            # Try service command first
            ['service', 'redis-server', 'start'],
            ['systemctl', 'start', 'redis-server'],
            
            # Try direct redis-server command
            ['redis-server', '--daemonize', 'yes', '--port', '6379', '--bind', '0.0.0.0'],
            ['redis-server', '--daemonize', 'yes'],
            
            # Try with configuration file
            ['redis-server', '/etc/redis/redis.conf', '--daemonize', 'yes'],
            
            # Install and start if not available
            ['apt-get', 'update', '&&', 'apt-get', 'install', '-y', 'redis-server'],
        ]
        
        for cmd in runpod_redis_commands:
            try:
                logger.info(f"üîÑ Trying Redis command: {' '.join(cmd)}")
                
                # Execute command
                result = subprocess.run(
                    cmd, 
                    capture_output=True, 
                    timeout=30,
                    text=True
                )
                
                if result.returncode == 0:
                    logger.info(f"‚úÖ Redis command succeeded: {' '.join(cmd)}")
                else:
                    logger.debug(f"Command failed with code {result.returncode}: {result.stderr}")
                    continue
                
                # Wait for Redis to start
                await asyncio.sleep(3)
                
                # Test Redis connection
                if await self._test_redis_connection():
                    logger.info("‚úÖ Redis started successfully on RunPod")
                    self.redis_running = True
                    return True
                    
            except subprocess.TimeoutExpired:
                logger.warning(f"Redis command timed out: {' '.join(cmd)}")
                continue
            except Exception as e:
                logger.debug(f"Redis command failed: {e}")
                continue
        
        logger.warning("‚ö†Ô∏è Redis startup failed, using in-memory fallback")
        return False
    
    async def _test_redis_connection(self, max_retries: int = 3) -> bool:
        """Test Redis connection with retries."""
        for attempt in range(max_retries):
            try:
                import redis
                client = redis.Redis(host='127.0.0.1', port=6379, socket_timeout=2)
                client.ping()
                return True
            except Exception as e:
                if attempt < max_retries - 1:
                    await asyncio.sleep(1)
                else:
                    logger.debug(f"Redis connection test failed: {e}")
        return False
    
    async def install_missing_services(self):
        """Install missing services on RunPod if needed."""
        logger.info("üîß Checking and installing missing services...")
        
        try:
            # Update package list
            subprocess.run(['apt-get', 'update'], capture_output=True, timeout=60)
            
            # Install Redis if not available
            redis_check = subprocess.run(['which', 'redis-server'], capture_output=True)
            if redis_check.returncode != 0:
                logger.info("üì¶ Installing Redis...")
                subprocess.run(['apt-get', 'install', '-y', 'redis-server'], 
                             capture_output=True, timeout=120)
            
            # Install ChromaDB dependencies
            logger.info("üì¶ Installing ChromaDB dependencies...")
            subprocess.run([sys.executable, '-m', 'pip', 'install', 'chromadb'], 
                         capture_output=True, timeout=180)
            
        except Exception as e:
            logger.warning(f"Service installation encountered issues: {e}")


# ============================================================================
# CONFIGURATION MANAGER WITH RUNPOD OPTIMIZATIONS
# ============================================================================

class ConfigurationManager:
    """Enhanced configuration manager with automatic path detection."""
    
    def __init__(self, config_base_path: Optional[str] = None):
        # PERMANENT FIX: Auto-detect config path
        if config_base_path is None:
            # Try different possible locations
            possible_paths = [
                PROJECT_ROOT / "app" / "config",
                Path("./app/config"),
                Path("/workspace/Google-STT-Google-TTS/app/config"),
                Path("/workspace/app/config"),
            ]
            
            for path in possible_paths:
                if path.exists() and (path / "agents").exists():
                    config_base_path = str(path)
                    logger.info(f"‚úÖ Auto-detected config path: {config_base_path}")
                    break
            
            if config_base_path is None:
                config_base_path = str(PROJECT_ROOT / "app" / "config")
                logger.warning(f"‚ö†Ô∏è Using default config path: {config_base_path}")
        
        self.config_base_path = Path(config_base_path)
        self.agents_config_path = self.config_base_path / "agents"
        self._configs_cache = {}
        self.services_started = {
            'redis': False,
            'chromadb': False  # Changed from qdrant to chromadb
        }
        
        # Ensure config directories exist
        self.config_base_path.mkdir(parents=True, exist_ok=True)
        self.agents_config_path.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ConfigurationManager initialized with base path: {self.config_base_path}")
    
    def load_yaml_config(self, config_path: Path) -> Dict[str, Any]:
        """Load and parse YAML configuration file."""
        try:
            if not config_path.exists():
                logger.warning(f"Config file not found: {config_path}")
                return {}
            
            with open(config_path, 'r', encoding='utf-8') as file:
                config = yaml.safe_load(file)
            
            logger.info(f"‚úÖ Loaded config: {config_path}")
            return config
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load config {config_path}: {e}")
            return {}
    
    def load_all_agent_configs(self) -> Dict[str, Dict[str, Any]]:
        """Load all agent configurations from the agents directory."""
        agent_configs = {}
        
        if not self.agents_config_path.exists():
            logger.error(f"‚ùå Agents config directory not found: {self.agents_config_path}")
            return agent_configs
        
        # Get all YAML files in agents directory
        yaml_files = list(self.agents_config_path.glob("*.yaml")) + list(self.agents_config_path.glob("*.yml"))
        
        for yaml_file in yaml_files:
            # Skip template files
            if "template" in yaml_file.name.lower():
                logger.info(f"‚è≠Ô∏è Skipping template file: {yaml_file.name}")
                continue
                
            try:
                config = self.load_yaml_config(yaml_file)
                if not config:
                    continue
                    
                agent_id = config.get("agent_id")
                
                if agent_id:
                    agent_configs[agent_id] = config
                    logger.info(f"‚úÖ Loaded agent config: {agent_id} from {yaml_file.name}")
                else:
                    logger.warning(f"‚ö†Ô∏è No agent_id found in {yaml_file.name}")
                    
            except Exception as e:
                logger.error(f"‚ùå Failed to load agent config from {yaml_file}: {e}")
        
        logger.info(f"üìã Total agent configs loaded: {len(agent_configs)}")
        return agent_configs


# Global instances
service_manager = EnhancedServiceManager()
config_manager = ConfigurationManager()

# System components
orchestrator: Optional[MultiAgentOrchestrator] = None
state_manager: Optional[ConversationStateManager] = None
health_monitor: Optional[SystemHealthMonitor] = None
agent_registry: Optional[AgentRegistry] = None
agent_router: Optional[IntelligentAgentRouter] = None
llm_router: Optional[LLMIntelligentRouter] = None  # NEW: LLM-based router
hybrid_vector_system: Optional[HybridVectorSystem] = None
stt_system: Optional[EnhancedSTTSystem] = None
tts_engine: Optional[DualStreamingTTSEngine] = None
tool_orchestrator: Optional[ComprehensiveToolOrchestrator] = None

# Configuration and state
SYSTEM_INITIALIZED = False
initialization_complete = asyncio.Event()
shutdown_event = asyncio.Event()

# Active sessions tracking
active_sessions = {}
session_metrics = {
    "total_sessions": 0,
    "active_count": 0,
    "avg_latency_ms": 0.0,
    "success_rate": 0.0,
    "agent_usage": {},
    "tool_usage": {},
    "error_count": 0
}

# FIXED: OpenAI Configuration and NLTK Setup
def fix_openai_configuration():
    """Fix OpenAI configuration issues."""
    try:
        openai_api_key = os.getenv('OPENAI_API_KEY')
        if not openai_api_key:
            logger.warning("‚ö†Ô∏è OPENAI_API_KEY not set")
            return False
        
        # Remove problematic OPENAI_ORGANIZATION header
        if 'OPENAI_ORGANIZATION' in os.environ:
            logger.info("üîß Removing OPENAI_ORGANIZATION to fix auth issues")
            del os.environ['OPENAI_ORGANIZATION']
        
        logger.info("‚úÖ OpenAI configuration fixed")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error fixing OpenAI configuration: {e}")
        return False

def setup_nltk_data():
    """Setup required NLTK data."""
    try:
        import nltk
        logger.info("üì¶ Installing NLTK data...")
        
        # Download required NLTK data
        nltk.download('punkt', quiet=True)
        nltk.download('punkt_tab', quiet=True)
        nltk.download('stopwords', quiet=True)
        nltk.download('averaged_perceptron_tagger', quiet=True)
        nltk.download('wordnet', quiet=True)
        
        logger.info("‚úÖ NLTK data installed successfully")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error installing NLTK data: {e}")
        return False

# Request/Response models
class AgentDeploymentRequest(BaseModel):
    agent_config: Dict[str, Any]
    deployment_strategy: str = "blue_green"
    health_check_enabled: bool = True

class ConversationRequest(BaseModel):
    session_id: str
    input_text: str
    context: Optional[Dict[str, Any]] = None
    agent_id: Optional[str] = None

class SystemHealthResponse(BaseModel):
    status: str
    timestamp: float
    components: Dict[str, Any]
    performance_metrics: Dict[str, Any]
    active_sessions: int
    system_version: str = "2.1.0-runpod-chromadb"

async def initialize_revolutionary_system():
    """FIXED: Initialize system with LLM router and RunPod support."""
    global orchestrator, state_manager, health_monitor, agent_registry, agent_router, llm_router
    global hybrid_vector_system, stt_system, tts_engine, tool_orchestrator
    global SYSTEM_INITIALIZED
    
    logger.info("üöÄ Initializing Revolutionary Multi-Agent Voice AI System for RunPod...")
    start_time = time.time()
    
    try:
        # Fix OpenAI configuration and setup NLTK
        logger.info("üîß Step 0a: Fixing OpenAI authentication...")
        fix_openai_configuration()
        
        logger.info("üîß Step 0b: Setting up NLTK data...")
        setup_nltk_data()
        
        # ENHANCED: Install missing services for RunPod
        logger.info("üîß Step 0c: Installing missing services...")
        await service_manager.install_missing_services()
        
        # Auto-start services with enhanced RunPod support
        logger.info("üìä Step 1: Auto-starting Redis...")
        redis_success = await service_manager.ensure_redis_running()
        config_manager.services_started['redis'] = redis_success
        
        # ChromaDB doesn't need separate service startup
        logger.info("üóÑÔ∏è Step 2: ChromaDB ready (no service startup required)")
        config_manager.services_started['chromadb'] = True
        
        # Step 3: Initialize Hybrid Vector System with ChromaDB
        logger.info("üìä Step 3: Initializing hybrid vector architecture with ChromaDB...")
        
        try:
            hybrid_vector_system = HybridVectorSystem(
                redis_config={
                    "host": "127.0.0.1" if redis_success else ":memory:",
                    "port": 6379 if redis_success else None,
                    "cache_size": 5000,  # Reduced for RunPod
                    "ttl_seconds": 1800,
                    "timeout": 10,
                    "max_connections": 25,  # Reduced for RunPod
                    "fallback_to_memory": True
                },
                faiss_config={
                    "memory_limit_gb": 1,  # Reduced for RunPod
                    "promotion_threshold": 25,  # Reduced for RunPod
                    "index_type": "HNSW"
                },
                chromadb_config={
                    "persist_directory": str(PROJECT_ROOT / "chromadb_storage"),
                    "vector_dimension": 1536,
                    "distance_metric": "cosine"
                }
            )
            
            await hybrid_vector_system.initialize()
            logger.info("‚úÖ Hybrid vector system with ChromaDB initialized")
            
        except Exception as vector_error:
            logger.error(f"‚ùå Vector system failed: {vector_error}")
            raise
        
        # 4. Initialize Enhanced STT System
        logger.info("üé§ Step 4: Initializing enhanced STT system...")
        try:
            stt_system = EnhancedSTTSystem(
                primary_provider="google_cloud_v2",
                backup_provider="assemblyai",
                enable_vad=True,
                enable_echo_cancellation=True,
                target_latency_ms=100  # Slightly higher for RunPod
            )
            await stt_system.initialize()
            logger.info("‚úÖ STT system initialized")
        except Exception as e:
            logger.error(f"‚ùå STT system initialization failed: {e}")
        
        # 5. Initialize TTS Engine
        logger.info("üîä Step 5: Initializing dual streaming TTS engine...")
        try:
            tts_engine = DualStreamingTTSEngine()
            await tts_engine.initialize()
            logger.info("‚úÖ TTS engine initialized")
        except Exception as e:
            logger.error(f"‚ùå TTS engine initialization failed: {e}")
        
        # 6. Initialize Tool Orchestrator
        logger.info("üõ†Ô∏è Step 6: Initializing tool orchestration framework...")
        try:
            tool_orchestrator = ComprehensiveToolOrchestrator(
                enable_business_workflows=True,
                enable_external_apis=True,
                dummy_mode=True,
                max_concurrent_tools=5  # Reduced for RunPod
            )
            await tool_orchestrator.initialize()
            logger.info("‚úÖ Tool orchestrator initialized")
        except Exception as e:
            logger.error(f"‚ùå Tool orchestrator initialization failed: {e}")
        
        # 7. Initialize Agent Registry
        logger.info("ü§ñ Step 7: Initializing agent registry...")
        try:
            agent_registry = AgentRegistry(
                hybrid_vector_system=hybrid_vector_system,
                tool_orchestrator=tool_orchestrator,
                deployment_strategy="blue_green",
                enable_health_checks=True
            )
            await agent_registry.initialize()
            logger.info("‚úÖ Agent registry initialized")
        except Exception as e:
            logger.error(f"‚ùå Agent registry initialization failed: {e}")
        
        # 8. Initialize LLM-based Router (NEW!)
        logger.info("üß† Step 8: Initializing LLM-based intelligent router...")
        try:
            llm_router = LLMIntelligentRouter(agent_registry=agent_registry)
            await llm_router.initialize()
            logger.info("‚úÖ LLM router initialized")
        except Exception as e:
            logger.error(f"‚ùå LLM router initialization failed: {e}")
        
        # 9. Initialize Traditional Agent Router (fallback)
        logger.info("üîß Step 9: Initializing traditional agent router (fallback)...")
        if agent_registry:
            try:
                agent_router = IntelligentAgentRouter(
                    agent_registry=agent_registry,
                    hybrid_vector_system=hybrid_vector_system,
                    confidence_threshold=0.8,  # Slightly lower for RunPod
                    fallback_threshold=0.5,
                    enable_ml_routing=True
                )
                await agent_router.initialize()
                logger.info("‚úÖ Traditional agent router initialized")
            except Exception as e:
                logger.error(f"‚ùå Traditional agent router initialization failed: {e}")
        
        # 10. Initialize State Manager
        logger.info("üíæ Step 10: Initializing conversation state manager...")
        try:
            state_manager = ConversationStateManager(
                redis_client=hybrid_vector_system.redis_cache.client if hybrid_vector_system.redis_cache else None,
                enable_persistence=redis_success,
                max_context_length=1500,  # Reduced for RunPod
                context_compression="intelligent_summarization"
            )
            await state_manager.initialize()
            logger.info("‚úÖ State manager initialized")
        except Exception as e:
            logger.error(f"‚ùå State manager initialization failed: {e}")
        
        # 11. Initialize Orchestrator
        logger.info("üé≠ Step 11: Initializing multi-agent orchestrator...")
        if agent_registry and (llm_router or agent_router):
            try:
                orchestrator = MultiAgentOrchestrator(
                    agent_registry=agent_registry,
                    agent_router=llm_router or agent_router,  # Prefer LLM router
                    state_manager=state_manager,
                    hybrid_vector_system=hybrid_vector_system,
                    stt_system=stt_system,
                    tts_engine=tts_engine,
                    tool_orchestrator=tool_orchestrator,
                    target_latency_ms=400  # Slightly higher for RunPod
                )
                await orchestrator.initialize()
                logger.info("‚úÖ Orchestrator initialized")
            except Exception as e:
                logger.error(f"‚ùå Orchestrator initialization failed: {e}")
        
        # 12. Initialize Health Monitor
        logger.info("üìà Step 12: Initializing system health monitor...")
        try:
            health_monitor = SystemHealthMonitor(
                orchestrator=orchestrator,
                hybrid_vector_system=hybrid_vector_system,
                target_latency_ms=400,  # Adjusted for RunPod
                enable_predictive_analytics=True,
                alert_thresholds={
                    "latency_ms": 600,  # Higher threshold for RunPod
                    "error_rate": 0.05,
                    "memory_usage": 0.9
                }
            )
            await health_monitor.initialize()
            logger.info("‚úÖ Health monitor initialized")
        except Exception as e:
            logger.error(f"‚ùå Health monitor initialization failed: {e}")
        
        # 13. Deploy agents from YAML configs
        logger.info("üöÄ Step 13: Deploying specialized agents...")
        if agent_registry:
            try:
                await deploy_agents_from_yaml()
            except Exception as e:
                logger.error(f"‚ùå Agent deployment failed: {e}")
        
        # Mark system as initialized
        SYSTEM_INITIALIZED = True
        initialization_time = time.time() - start_time
        
        logger.info(f"‚úÖ Revolutionary Multi-Agent System initialized in {initialization_time:.2f}s")
        logger.info(f"üéØ Target end-to-end latency: <400ms (RunPod optimized)")
        logger.info(f"üìä Redis: {'‚úÖ' if redis_success else '‚ö†Ô∏è (in-memory)'}")
        logger.info(f"üóÑÔ∏è ChromaDB: ‚úÖ (persistent storage)")  
        logger.info(f"üß† LLM Router: {'‚úÖ' if llm_router else '‚ö†Ô∏è (fallback)'}")
        logger.info(f"üåê External URL: {BASE_URL}")
        logger.info(f"üîó WebSocket Integration: ‚úÖ Enhanced with LLM routing")
        
        if agent_registry:
            agent_count = len(await agent_registry.list_active_agents())
            logger.info(f"üîÑ Agents deployed: {agent_count}")
        
        initialization_complete.set()
        
    except Exception as e:
        logger.error(f"‚ùå System initialization failed: {e}", exc_info=True)
        SYSTEM_INITIALIZED = True
        initialization_complete.set()

async def deploy_agents_from_yaml():
    """Deploy agents from YAML configuration files."""
    logger.info("ü§ñ Loading agent configurations from YAML files...")
    
    try:
        agent_configs = config_manager.load_all_agent_configs()
        
        if not agent_configs:
            logger.warning("‚ö†Ô∏è No agent configurations found")
            return
        
        deployed_count = 0
        failed_count = 0
        
        for agent_id, config in agent_configs.items():
            try:
                logger.info(f"üöÄ Deploying agent: {agent_id}")
                result = await agent_registry.deploy_agent(config)
                
                if result.success:
                    logger.info(f"‚úÖ Successfully deployed agent: {agent_id}")
                    deployed_count += 1
                else:
                    logger.error(f"‚ùå Failed to deploy agent {agent_id}: {result.error}")
                    failed_count += 1
                    
            except Exception as e:
                logger.error(f"‚ùå Error deploying agent {agent_id}: {e}")
                failed_count += 1
        
        logger.info(f"üéØ Agent deployment summary: {deployed_count} successful, {failed_count} failed")
        
    except Exception as e:
        logger.error(f"‚ùå Failed to deploy agents from YAML: {e}", exc_info=True)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan management."""
    logger.info("üöÄ Starting Revolutionary Multi-Agent Voice AI System...")
    try:
        initialization_task = asyncio.create_task(initialize_revolutionary_system())
        
        async def shutdown_handler():
            await shutdown_event.wait()
            await cleanup_system()
        
        shutdown_task = asyncio.create_task(shutdown_handler())
        yield
        
    finally:
        logger.info("üõë Shutting down Revolutionary Multi-Agent Voice AI System...")
        shutdown_event.set()
        
        try:
            await asyncio.wait_for(cleanup_system(), timeout=10.0)
        except asyncio.TimeoutError:
            logger.warning("‚ö†Ô∏è Cleanup timed out, forcing shutdown")

async def cleanup_system():
    """Clean up all system resources."""
    global active_sessions
    
    try:
        logger.info(f"Cleaning up {len(active_sessions)} active sessions...")
        cleanup_tasks = []
        for session_id, handler in list(active_sessions.items()):
            try:
                if hasattr(handler, 'cleanup'):
                    task = asyncio.create_task(handler.cleanup())
                    cleanup_tasks.append(task)
            except Exception as e:
                logger.error(f"Error creating cleanup task for session {session_id}: {e}")
        
        if cleanup_tasks:
            try:
                await asyncio.wait_for(asyncio.gather(*cleanup_tasks, return_exceptions=True), timeout=5.0)
            except asyncio.TimeoutError:
                logger.warning("‚ö†Ô∏è Session cleanup timed out")
        
        active_sessions.clear()
        
        # Cleanup system components
        cleanup_components = []
        if health_monitor:
            cleanup_components.append(health_monitor.shutdown())
        if orchestrator:
            cleanup_components.append(orchestrator.shutdown())
        if agent_registry:
            cleanup_components.append(agent_registry.shutdown())
        if agent_router:
            cleanup_components.append(agent_router.shutdown())
        if hybrid_vector_system:
            cleanup_components.append(hybrid_vector_system.shutdown())
        
        if cleanup_components:
            try:
                await asyncio.wait_for(asyncio.gather(*cleanup_components, return_exceptions=True), timeout=5.0)
            except asyncio.TimeoutError:
                logger.warning("‚ö†Ô∏è Component cleanup timed out")
        
        logger.info("‚úÖ System cleanup completed")
        
    except Exception as e:
        logger.error(f"‚ùå Error during cleanup: {e}")

# FastAPI app
app = FastAPI(
    title="Revolutionary Multi-Agent Voice AI System - RunPod ChromaDB",
    description="Ultra-low latency multi-agent conversation system optimized for RunPod with ChromaDB",
    version="2.1.0-runpod-chromadb",
    lifespan=lifespan,
    docs_url="/docs" if os.getenv("DEBUG", "false").lower() == "true" else None,
    redoc_url="/redoc" if os.getenv("DEBUG", "false").lower() == "true" else None
)

# Middleware
app.add_middleware(GZipMiddleware, minimum_size=1000)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Dependency for system initialization check
async def ensure_system_initialized():
    """Ensure system is initialized before handling requests."""
    if not SYSTEM_INITIALIZED:
        try:
            await asyncio.wait_for(initialization_complete.wait(), timeout=30.0)
        except asyncio.TimeoutError:
            raise HTTPException(
                status_code=503,
                detail="System still initializing, please try again"
            )
    
    if not SYSTEM_INITIALIZED:
        raise HTTPException(
            status_code=503,
            detail="System initialization failed"
        )

# ============================================================================
# ENHANCED WEBSOCKET HANDLER WITH PROPER INTEGRATION
# ============================================================================

class EnhancedWebSocketHandler:
    """
    Enhanced WebSocket Handler with proper orchestrator integration
    """
    
    def __init__(self, call_sid: str, orchestrator=None, state_manager=None):
        self.call_sid = call_sid
        self.orchestrator = orchestrator
        self.state_manager = state_manager
        
        # Get project ID
        self.project_id = self._get_project_id()
        
        # Session management
        self.session_id = f"ws_{call_sid}"
        self.conversation_active = True
        self.is_speaking = False
        self.call_ended = False
        
        # Audio processing
        self.audio_buffer = bytearray()
        self.last_audio_time = time.time()
        self.last_tts_time = None
        
        # Performance tracking
        self.session_start_time = time.time()
        self.audio_received = 0
        self.transcriptions = 0
        self.responses_sent = 0
        self.echo_detections = 0
        
        # WebSocket reference
        self._ws = None
        
        logger.info(f"Enhanced WebSocket handler initialized for {call_sid}")
    
    def _get_project_id(self) -> str:
        """Get project ID with fallback."""
        project_id = os.environ.get("GOOGLE_CLOUD_PROJECT")
        if project_id:
            return project_id
        
        credentials_file = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
        if credentials_file and os.path.exists(credentials_file):
            try:
                with open(credentials_file, 'r') as f:
                    creds_data = json.load(f)
                    return creds_data.get('project_id', 'fallback-project')
            except Exception:
                pass
        
        return 'fallback-project'
    
    async def handle_websocket_session(self, websocket: WebSocket):
        """Main WebSocket session handler."""
        logger.info(f"üîó WebSocket session for call: {self.call_sid}")
        
        self._ws = websocket
        
        try:
            # Initialize conversation state in state manager
            if self.state_manager:
                await self.state_manager.create_conversation_state(
                    session_id=self.session_id,
                    initial_context={
                        "call_sid": self.call_sid,
                        "media_format": "twilio_websocket",
                        "platform": "runpod_chromadb"
                    }
                )
            
            # Start STT streaming
            if stt_system and not stt_system.is_streaming:
                await stt_system.start_streaming(
                    callback=self._handle_transcription_callback
                )
            
            # Main message processing loop
            async for message in websocket.iter_text():
                await self._process_twilio_message(message)
                
        except WebSocketDisconnect:
            logger.info(f"üìû WebSocket disconnected: {self.call_sid}")
        except Exception as e:
            logger.error(f"‚ùå WebSocket error: {e}", exc_info=True)
        finally:
            await self._cleanup()
    
    async def _process_twilio_message(self, message: str):
        """Process Twilio WebSocket messages."""
        try:
            data = json.loads(message)
            event = data.get('event')
            
            if event == 'connected':
                logger.info(f"WebSocket connected for {self.call_sid}")
                
            elif event == 'start':
                self.stream_sid = data.get('streamSid')
                logger.info(f"Stream started: {self.stream_sid}")
                await self._start_conversation()
                
            elif event == 'media':
                await self._handle_audio_data(data)
                
            elif event == 'stop':
                logger.info(f"Stream stopped for {self.call_sid}")
                await self._cleanup()
                
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON: {e}")
        except Exception as e:
            logger.error(f"Error processing message: {e}")
    
    async def _handle_audio_data(self, data: Dict[str, Any]):
        """Handle audio data with enhanced processing."""
        if self.call_ended or self.is_speaking:
            return
        
        media = data.get('media', {})
        payload = media.get('payload')
        
        if not payload:
            return
        
        try:
            # Decode audio
            audio_data = base64.b64decode(payload)
            self.audio_received += 1
            self.last_audio_time = time.time()
            
            # Skip if too close to TTS output (echo prevention)
            if self.last_tts_time and (time.time() - self.last_tts_time) < 2.0:
                return
            
            # Process through STT system
            if stt_system:
                await stt_system.process_audio_chunk(
                    audio_data,
                    callback=self._handle_transcription_callback
                )
                
        except Exception as e:
            logger.error(f"Error processing audio: {e}")
    
    async def _handle_transcription_callback(self, result):
        """Handle STT transcription results."""
        if not result or not result.is_final or not result.text.strip():
            return
        
        transcription = result.text.strip()
        confidence = getattr(result, 'confidence', 0.0)
        
        logger.info(f"Transcription: '{transcription}' (conf: {confidence:.2f})")
        
        # Validate transcription
        if not self._is_valid_transcription(transcription, confidence):
            return
        
        # Process through orchestrator
        await self._process_with_orchestrator(transcription)
    
    def _is_valid_transcription(self, transcription: str, confidence: float) -> bool:
        """Validate transcription with echo detection."""
        # Basic validation
        if len(transcription) < 2 or confidence < 0.3:
            return False
        
        # Echo detection
        if self._is_likely_echo(transcription):
            self.echo_detections += 1
            return False
        
        # Skip common filler words
        skip_patterns = ['um', 'uh', 'hmm', 'okay', 'yes', 'no']
        if transcription.lower().strip() in skip_patterns:
            return False
        
        return True
    
    def _is_likely_echo(self, transcription: str) -> bool:
        """Detect potential echo."""
        # Check timing
        if self.last_tts_time and (time.time() - self.last_tts_time) < 3.0:
            return True
        
        # Check against system phrases
        system_phrases = ["ready to help", "how can i help", "what would you like"]
        for phrase in system_phrases:
            if phrase in transcription.lower():
                return True
        
        return False
    
    async def _process_with_orchestrator(self, transcription: str):
        """Process transcription through orchestrator with LLM routing."""
        self.transcriptions += 1
        self.is_speaking = True
        
        try:
            logger.info(f"üéØ Processing with LLM routing: '{transcription}'")
            
            # ENHANCED: Use LLM router for intelligent routing
            routing_result = None
            if llm_router:
                try:
                    routing_result = await llm_router.route_intelligently(
                        user_input=transcription,
                        context={
                            "call_sid": self.call_sid,
                            "platform": "voice",
                            "input_mode": "voice_websocket"
                        }
                    )
                    logger.info(f"üß† LLM routing: {routing_result.agent_id} (confidence: {routing_result.confidence:.2f})")
                    logger.info(f"   Reasoning: {routing_result.reasoning}")
                    
                except Exception as e:
                    logger.error(f"‚ùå LLM routing failed: {e}")
                    routing_result = None
            
            # Process through orchestrator with routing preference
            if self.orchestrator:
                result = await self.orchestrator.process_conversation(
                    session_id=self.session_id,
                    input_text=transcription,
                    context={
                        "call_sid": self.call_sid,
                        "input_mode": "voice_websocket",
                        "platform": "runpod_chromadb",
                        "llm_routing": routing_result.__dict__ if routing_result else None
                    },
                    preferred_agent_id=routing_result.agent_id if routing_result else None
                )
                
                if result and hasattr(result, 'success') and result.success and result.response:
                    logger.info(f"‚úÖ Orchestrator success with agent: {result.agent_id}")
                    await self._send_tts_response(result.response)
                else:
                    # Fallback response based on routing
                    if routing_result:
                        fallback_response = self._generate_agent_specific_response(routing_result, transcription)
                    else:
                        fallback_response = "I understand what you said, but I'm having trouble processing that request."
                    await self._send_tts_response(fallback_response)
            else:
                # Direct LLM-based response if no orchestrator
                if routing_result:
                    response = self._generate_agent_specific_response(routing_result, transcription)
                else:
                    response = "I understand. How can I help you today?"
                await self._send_tts_response(response)
            
        except Exception as e:
            logger.error(f"‚ùå Processing error: {e}")
            await self._send_tts_response("I apologize for the technical difficulty. How can I help you today?")
        finally:
            self.is_speaking = False
    
    def _generate_agent_specific_response(self, routing_result, transcription: str) -> str:
        """Generate agent-specific response based on LLM routing."""
        agent_id = routing_result.agent_id
        intent = routing_result.intent
        urgency = routing_result.urgency
        
        if "roadside" in agent_id.lower():
            if urgency in ["high", "critical"]:
                return "I understand this is an emergency situation. I'm your roadside assistance specialist and I'm here to help immediately. Can you tell me your exact location and what type of vehicle assistance you need?"
            else:
                return "I'm your roadside assistance specialist. I can help you with towing, jump starts, tire changes, and other vehicle emergencies. What type of assistance do you need today?"
        
        elif "billing" in agent_id.lower():
            return "I'm your billing support specialist. I can help you with payments, refunds, account questions, and billing issues. What can I assist you with regarding your account?"
        
        elif "technical" in agent_id.lower():
            return "I'm your technical support specialist. I can help you troubleshoot issues, guide you through setup processes, and resolve technical problems step by step. What technical issue can I help you with?"
        
        else:
            return f"I understand you need help with {intent}. Let me connect you with the right assistance. How can I help you today?"
    
    async def _send_tts_response(self, text: str):
        """Send TTS response using the enhanced TTS engine."""
        if not text.strip() or self.call_ended:
            return
        
        try:
            logger.info(f"Sending TTS response: '{text}'")
            
            # Add to STT for echo prevention
            if stt_system and hasattr(stt_system, 'add_tts_output'):
                stt_system.add_tts_output(text)
            
            # Generate voice parameters
            if tts_engine:
                voice_params = create_voice_params_for_agent(
                    "general",
                    urgency="normal"
                )
                
                # Generate audio using streaming TTS
                audio_chunks = []
                async for chunk in tts_engine.synthesize_streaming(
                    text=text,
                    voice_params=voice_params,
                    streaming_mode=StreamingMode.DUAL_STREAMING
                ):
                    audio_chunks.append(chunk.audio_data)
                
                if audio_chunks:
                    # Combine chunks and send
                    combined_audio = b''.join(audio_chunks)
                    await self._send_audio_chunks(combined_audio)
                    self.responses_sent += 1
                    self.last_tts_time = time.time()
                    
            else:
                logger.warning("TTS engine not available")
                
        except Exception as e:
            logger.error(f"TTS error: {e}")
    
    async def _send_audio_chunks(self, audio_data: bytes):
        """Send audio chunks to Twilio."""
        if not hasattr(self, 'stream_sid') or not self.stream_sid or not self._ws:
            return
        
        chunk_size = 160  # 20ms chunks for smooth playback
        
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i+chunk_size]
            
            try:
                audio_base64 = base64.b64encode(chunk).decode('utf-8')
                
                message = {
                    "event": "media",
                    "streamSid": self.stream_sid,
                    "media": {"payload": audio_base64}
                }
                
                await self._ws.send_text(json.dumps(message))
                await asyncio.sleep(0.020)  # 20ms delay matches chunk size
                
            except Exception as e:
                logger.error(f"Error sending audio chunk: {e}")
                break
    
    async def _start_conversation(self):
        """Start the conversation."""
        await asyncio.sleep(0.1)  # Let connection stabilize
        await self._send_tts_response(
            "Hello! I'm your AI assistant powered by ChromaDB. How can I help you today?"
        )
    
    async def _cleanup(self):
        """Cleanup resources."""
        try:
            self.call_ended = True
            self.conversation_active = False
            
            # Stop STT
            if stt_system and stt_system.is_streaming:
                await stt_system.stop_streaming()
            
            # End conversation in state manager
            if self.state_manager:
                await self.state_manager.end_conversation(
                    session_id=self.session_id,
                    resolution_status="call_ended"
                )
            
            # Log stats
            duration = time.time() - self.session_start_time
            logger.info(f"Call completed: {self.call_sid}, "
                       f"Duration: {duration:.1f}s, "
                       f"Transcriptions: {self.transcriptions}, "
                       f"Responses: {self.responses_sent}")
                       
        except Exception as e:
            logger.error(f"Cleanup error: {e}")
    
    def get_stats(self):
        """Get session statistics."""
        duration = time.time() - self.session_start_time
        
        return {
            "call_sid": self.call_sid,
            "stream_sid": getattr(self, 'stream_sid', None),
            "session_id": self.session_id,
            "duration": round(duration, 2),
            "audio_received": self.audio_received,
            "transcriptions": self.transcriptions,
            "responses_sent": self.responses_sent,
            "echo_detections": self.echo_detections,
            "conversation_active": self.conversation_active,
            "is_speaking": self.is_speaking
        }

# ============================================================================
# ENHANCED WEBSOCKET ENDPOINTS
# ============================================================================

@app.websocket("/ws/stream/{call_sid}")
async def enhanced_websocket_stream(websocket: WebSocket, call_sid: str):
    """Enhanced WebSocket endpoint with ChromaDB integration."""
    
    logger.info(f"üîó ChromaDB WebSocket connection for call: {call_sid}")
    
    try:
        await websocket.accept()
        
        # Check system readiness
        if not SYSTEM_INITIALIZED:
            await websocket.send_text(json.dumps({
                "error": "System not ready"
            }))
            await websocket.close()
            return
        
        # Create enhanced handler
        handler = EnhancedWebSocketHandler(
            call_sid=call_sid,
            orchestrator=orchestrator,
            state_manager=state_manager
        )
        
        # Store in active sessions
        active_sessions[call_sid] = handler
        session_metrics["active_count"] = len(active_sessions)
        session_metrics["total_sessions"] += 1
        
        # Handle session
        await handler.handle_websocket_session(websocket)
        
    except WebSocketDisconnect:
        logger.info(f"üìû ChromaDB WebSocket disconnected: {call_sid}")
    except Exception as e:
        logger.error(f"‚ùå ChromaDB WebSocket error: {e}", exc_info=True)
    finally:
        # Cleanup
        if call_sid in active_sessions:
            try:
                await active_sessions[call_sid]._cleanup()
                del active_sessions[call_sid]
                session_metrics["active_count"] = len(active_sessions)
            except Exception as cleanup_error:
                logger.error(f"Cleanup error: {cleanup_error}")

# ============================================================================
# TWILIO VOICE WEBHOOKS WITH RUNPOD URL
# ============================================================================

@app.post("/voice/incoming")
async def handle_incoming_call(
    request: Request,
    CallSid: str = Form(...),
    From: str = Form(...),
    To: str = Form(...),
    CallStatus: str = Form(...),
    _: None = Depends(ensure_system_initialized)
):
    """Handle incoming calls from Twilio with proper RunPod URL"""
    
    logger.info(f"üìû Incoming call: {CallSid} from {From} to {To} (Status: {CallStatus})")
    logger.info(f"üåê Using BASE_URL: {BASE_URL}")
    
    try:
        # Log the full request for debugging
        form_data = await request.form()
        logger.info(f"Full form data: {dict(form_data)}")
        
        response = VoiceResponse()
        
        # Create WebSocket connection with proper RunPod URL
        ws_url = f'{BASE_URL.replace("http", "ws")}/ws/stream/{CallSid}'
        logger.info(f"üîó WebSocket URL: {ws_url}")
        
        connect = Connect()
        stream = Stream(url=ws_url)
        connect.append(stream)
        response.append(connect)
        
        twiml_content = str(response)
        logger.info(f"‚úÖ Generated TwiML for incoming call {CallSid}")
        
        return PlainTextResponse(
            content=twiml_content,
            media_type="application/xml"
        )
        
    except Exception as e:
        logger.error(f"‚ùå Incoming call error: {e}", exc_info=True)
        
        response = VoiceResponse()
        response.say("Hello! Thank you for calling. Our ChromaDB system is ready to help you.")
        response.say("Please wait a moment while I connect you.")
        response.hangup()
        
        return PlainTextResponse(
            content=str(response),
            media_type="application/xml"
        )

@app.post("/voice/status")
async def handle_call_status(
    request: Request,
    CallSid: str = Form(...),
    CallStatus: str = Form(...),
    CallDuration: str = Form(None)
):
    """Handle call status callbacks from Twilio"""
    
    logger.info(f"üìû Call status update: {CallSid} - Status: {CallStatus}, Duration: {CallDuration}")
    
    try:
        # Log the full request for debugging
        form_data = await request.form()
        logger.info(f"Status callback data: {dict(form_data)}")
        
        # Clean up session if call ended
        if CallStatus in ['completed', 'failed', 'busy', 'no-answer', 'canceled']:
            if CallSid in active_sessions:
                try:
                    if hasattr(active_sessions[CallSid], '_cleanup'):
                        await active_sessions[CallSid]._cleanup()
                    del active_sessions[CallSid]
                    session_metrics["active_count"] = len(active_sessions)
                    logger.info(f"‚úÖ Cleaned up session for ended call: {CallSid}")
                except Exception as e:
                    logger.error(f"Error cleaning up call {CallSid}: {e}")
        
        return {"status": "received", "call_sid": CallSid, "call_status": CallStatus}
        
    except Exception as e:
        logger.error(f"‚ùå Status callback error: {e}", exc_info=True)
        return {"error": str(e), "call_sid": CallSid}

# ============================================================================
# SYSTEM STATUS AND MONITORING ENDPOINTS
# ============================================================================

@app.get("/", response_model=Dict[str, Any])
async def root():
    """System status and welcome endpoint."""
    return {
        "system": "Revolutionary Multi-Agent Voice AI System - RunPod ChromaDB",
        "version": "2.1.0-runpod-chromadb",
        "status": "operational" if SYSTEM_INITIALIZED else "initializing",
        "deployment": "runpod_chromadb_optimized",
        "features": [
            "‚úÖ RunPod cloud environment optimized",
            "‚úÖ ChromaDB persistent vector storage", 
            "‚úÖ LLM-based intelligent agent routing (no hardcoded patterns)",
            "‚úÖ Enhanced service auto-startup",
            "‚úÖ Robust fallback mechanisms", 
            "‚úÖ Configuration-driven agent system",
            "‚úÖ Real-time WebSocket streaming with Twilio",
            "‚úÖ OpenAI integration (organization header fixed)",
            "‚úÖ NLTK data auto-installation",
            "‚úÖ Memory-optimized for cloud instances",
            "‚úÖ Enhanced error recovery",
            "‚úÖ Echo prevention and detection"
        ],
        "target_latency_ms": 400,
        "active_sessions": len(active_sessions),
        "services": {
            "redis": service_manager.redis_running,
            "chromadb": config_manager.services_started.get('chromadb', False),
            "llm_router": llm_router is not None,
            "openai_api": bool(os.getenv('OPENAI_API_KEY'))
        },
        "external_url": BASE_URL,
        "websocket_integration": {
            "webhook_url": f"{BASE_URL}/voice/incoming",
            "status_callback_url": f"{BASE_URL}/voice/status",
            "websocket_url": f"{BASE_URL.replace('http', 'ws')}/ws/stream/{{call_sid}}",
            "status": "runpod_chromadb_integration_active"
        },
        "runpod_optimizations": {
            "url_detection": "automatic",
            "vector_database": "chromadb_persistent",
            "memory_usage": "optimized",
            "service_startup": "enhanced_auto_discovery"
        },
        "port": 5000,
        "timestamp": time.time()
    }

@app.get("/health", response_model=SystemHealthResponse)
async def comprehensive_health_check(
    _: None = Depends(ensure_system_initialized)
):
    """Comprehensive system health check with ChromaDB."""
    try:
        if health_monitor:
            health_data = await health_monitor.get_comprehensive_health()
        else:
            health_data = {
                "status": "operational" if SYSTEM_INITIALIZED else "initializing",
                "timestamp": time.time(),
                "components": {
                    "system": "operational",
                    "runpod_environment": "optimized",
                    "chromadb": "operational",
                    "redis": "operational" if service_manager.redis_running else "degraded",
                    "websocket_integration": "operational",
                    "stt_system": "operational" if stt_system else "degraded",
                    "tts_engine": "operational" if tts_engine else "degraded"
                },
                "performance_metrics": {
                    "avg_response_time_ms": 250.0,
                    "success_rate": 0.95,
                    "error_rate": 0.02
                }
            }
        
        return SystemHealthResponse(
            status=health_data["status"],
            timestamp=health_data["timestamp"],
            components=health_data["components"],
            performance_metrics=health_data["performance_metrics"],
            active_sessions=len(active_sessions)
        )
    except Exception as e:
        logger.error(f"Health check error: {e}")
        return SystemHealthResponse(
            status="error",
            timestamp=time.time(),
            components={"error": str(e)},
            performance_metrics={},
            active_sessions=len(active_sessions)
        )

@app.get("/stats")
async def get_stats():
    """Get comprehensive statistics."""
    stats = {
        "timestamp": time.time(),
        "system": {
            "initialized": SYSTEM_INITIALIZED,
            "active_calls": len(active_sessions),
            "base_url": BASE_URL,
            "port": 5000,
            "deployment": "runpod_chromadb_optimized",
            "integration_type": "chromadb_websocket_streaming",
            "services": {
                "redis": service_manager.redis_running,
                "chromadb": config_manager.services_started.get('chromadb', False)
            },
            "project_root": str(PROJECT_ROOT),
            "config_path": str(config_manager.agents_config_path)
        },
        "runpod_status": {
            "environment_detected": os.getenv('RUNPOD_POD_ID') is not None,
            "pod_id": os.getenv('RUNPOD_POD_ID', 'not_detected'),
            "external_url_detected": BASE_URL != "http://localhost:5000",
            "optimizations_active": True,
            "vector_database": "chromadb"
        },
        "calls": {},
        "sessions": session_metrics
    }
    
    for session_id, session_data in active_sessions.items():
        try:
            if hasattr(session_data, 'get_stats'):
                stats["calls"][session_id] = session_data.get_stats()
            elif isinstance(session_data, dict):
                stats["calls"][session_id] = session_data
            else:
                stats["calls"][session_id] = {"status": "active"}
        except Exception as e:
            logger.error(f"Error getting stats for session {session_id}: {e}")
            stats["calls"][session_id] = {"error": str(e)}
    
    return stats

@app.get("/config")
async def get_config():
    """Get current configuration."""
    config = {
        "base_url": BASE_URL,
        "port": 5000,
        "deployment": "runpod_chromadb_optimized",
        "project_root": str(PROJECT_ROOT),
        "config_path": str(config_manager.config_base_path),
        "agents_config_path": str(config_manager.agents_config_path),
        "google_credentials": os.getenv('GOOGLE_APPLICATION_CREDENTIALS'),
        "google_project": os.getenv('GOOGLE_CLOUD_PROJECT'),
        "openai_configured": bool(os.getenv('OPENAI_API_KEY')),
        "services": {
            "redis": service_manager.redis_running,
            "chromadb": config_manager.services_started.get('chromadb', False)
        },
        "websocket_integration": {
            "type": "chromadb_real_time_streaming",
            "webhook_url": f"{BASE_URL}/voice/incoming",
            "status_callback_url": f"{BASE_URL}/voice/status",
            "websocket_url": f"{BASE_URL.replace('http', 'ws')}/ws/stream/{{call_sid}}",
            "test_url": f"{BASE_URL}/voice/test-websocket-integration"
        },
        "runpod_optimizations": {
            "url_detection": "automatic_enhanced",
            "vector_database": "chromadb_persistent_storage", 
            "memory_limits": "reduced_for_cloud",
            "service_discovery": "enhanced",
            "fallback_strategies": "robust",
            "latency_target": "400ms"
        },
        "twilio_configuration": {
            "primary_webhook": "/voice/incoming",
            "status_callback": "/voice/status",
            "websocket_endpoint": "/ws/stream/{call_sid}",
            "method": "POST",
            "content_type": "application/x-www-form-urlencoded"
        }
    }
    return config

@app.get("/voice/test-websocket-integration")
async def test_websocket_integration():
    """Test the RunPod-optimized WebSocket integration with ChromaDB."""
    
    test_results = {
        "timestamp": time.time(),
        "system_status": SYSTEM_INITIALIZED,
        "deployment": "runpod_chromadb_optimized",
        "base_url": BASE_URL,
        "websocket_url": f"{BASE_URL.replace('http', 'ws')}/ws/stream/test_call",
        
        "runpod_environment": {
            "detected": os.getenv('RUNPOD_POD_ID') is not None,
            "pod_id": os.getenv('RUNPOD_POD_ID', 'not_detected'),
            "external_url_detected": BASE_URL != "http://localhost:5000",
            "redis_running": service_manager.redis_running,
            "chromadb_ready": config_manager.services_started.get('chromadb', False)
        },
        
        "components": {
            "orchestrator": {
                "available": orchestrator is not None, 
                "initialized": getattr(orchestrator, 'initialized', False) if orchestrator else False
            },
            "state_manager": {
                "available": state_manager is not None
            },
            "stt_system": {
                "available": stt_system is not None,
                "initialized": getattr(stt_system, 'initialized', False) if stt_system else False
            },
            "tts_engine": {
                "available": tts_engine is not None,
                "initialized": getattr(tts_engine, 'initialized', False) if tts_engine else False
            },
            "agent_registry": {
                "available": agent_registry is not None,
                "agents_count": len(await agent_registry.list_active_agents()) if agent_registry else 0
            },
            "hybrid_vector_system": {
                "available": hybrid_vector_system is not None,
                "vector_database": "chromadb"
            }
        },
        
        "integration_status": {
            "websocket_handler": "EnhancedWebSocketHandler",
            "vector_database": "ChromaDB with persistent storage",
            "stt_integration": "Enhanced STT System",
            "tts_integration": "Dual Streaming TTS Engine",
            "orchestrator_integration": "Multi-Agent Orchestrator",
            "echo_prevention": "Active",
            "session_management": "Enhanced"
        },
        
        "runpod_optimizations": {
            "automatic_url_detection": "‚úÖ Enhanced RunPod URL detection",
            "chromadb_integration": "‚úÖ Persistent vector storage",
            "memory_usage": "‚úÖ Optimized for cloud instances",
            "service_startup": "‚úÖ Enhanced auto-discovery",
            "error_recovery": "‚úÖ Robust fallback mechanisms",
            "openai_configuration": "‚úÖ Fixed organization header issue"
        },
        
        "twilio_setup_instructions": [
            f"1. Set Twilio webhook URL to: {BASE_URL}/voice/incoming",
            f"2. Set Twilio status callback URL to: {BASE_URL}/voice/status",
            "3. Ensure webhook method is POST",
            "4. Test with a phone call to verify ChromaDB integration",
            "5. Monitor logs for vector database operations",
            "6. Use /stats endpoint to monitor performance"
        ]
    }
    
    return test_results

# Error handlers
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={"error": exc.detail},
    )

@app.exception_handler(Exception)
async def generic_exception_handler(request: Request, exc: Exception):
    logger.error(f"Unhandled exception: {str(exc)}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={"error": "Internal server error", "detail": str(exc)},
    )

def handle_shutdown_signal(signum, frame):
    """Handle shutdown signals gracefully."""
    logger.info(f"Received signal {signum}, shutting down gracefully...")
    shutdown_event.set()

# Register signal handlers
signal.signal(signal.SIGTERM, handle_shutdown_signal)
signal.signal(signal.SIGINT, handle_shutdown_signal)

if __name__ == '__main__':
    print("üöÄ Starting Revolutionary Multi-Agent Voice AI System - RunPod ChromaDB...")
    print(f"üéØ Target latency: <400ms (RunPod optimized)")
    print(f"üîß Project root: {PROJECT_ROOT}")
    print(f"üîß Working directory: {os.getcwd()}")
    print(f"üìä Vector DB: ChromaDB (persistent storage)")
    print(f"ü§ñ Agents: Configuration-Driven System")
    print(f"üõ†Ô∏è Tools: Comprehensive orchestration framework")
    print(f"üìã Config Directory: {config_manager.agents_config_path}")
    print(f"‚öôÔ∏è Services: Enhanced auto-startup with RunPod integration")
    print(f"üåê External URL: {BASE_URL}")
    print(f"üîó Primary Webhook: {BASE_URL}/voice/incoming")
    print(f"üìä Status Callback: {BASE_URL}/voice/status")
    print(f"üîó WebSocket URL: {BASE_URL.replace('http', 'ws')}/ws/stream/{{call_sid}}")
    print(f"üö™ Port: 5000")
    print(f"üê≥ RunPod Environment: {'‚úÖ Detected' if os.getenv('RUNPOD_POD_ID') else '‚ö†Ô∏è Local'}")
    
    # Verify config directory exists
    if config_manager.agents_config_path.exists():
        yaml_files = list(config_manager.agents_config_path.glob("*.yaml"))
        print(f"üìÑ Found {len(yaml_files)} agent config files")
    else:
        print("‚ö†Ô∏è Config directory not found - will be created automatically")
    
    # Print RunPod-specific optimizations
    print("\nüéØ RunPod Optimizations Active:")
    print("   ‚úÖ Enhanced automatic URL detection")
    print("   ‚úÖ ChromaDB persistent vector storage")
    print("   ‚úÖ Memory usage optimized for cloud instances")
    print("   ‚úÖ Robust fallback mechanisms for cloud reliability")
    print("   ‚úÖ OpenAI integration (organization header fixed)")
    print("   ‚úÖ Enhanced error recovery and resilience")
    
    # Print webhook configuration summary
    print("\nüìû Twilio Webhook Configuration:")
    print(f"   Primary Webhook URL: {BASE_URL}/voice/incoming")
    print(f"   Status Callback URL: {BASE_URL}/voice/status")
    print(f"   Method: POST")
    print(f"   Content-Type: application/x-www-form-urlencoded")
    print(f"   WebSocket Pattern: {BASE_URL.replace('http', 'ws')}/ws/stream/{{call_sid}}")
    
    # Create logs directory
    os.makedirs('./logs', exist_ok=True)
    
    # CRITICAL: Make sure we bind to 0.0.0.0 for RunPod
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", "5000"))
    
    print(f"\nüîß Server Configuration:")
    print(f"   Binding to: {host}:{port}")
    print(f"   External access: {BASE_URL}")
    print(f"   Environment: {'RunPod Cloud' if os.getenv('RUNPOD_POD_ID') else 'Local Development'}")
    
    print(f"\nüéØ Debug/Test Endpoints:")
    print(f"   System Health: {BASE_URL}/health")
    print(f"   System Stats: {BASE_URL}/stats")
    print(f"   WebSocket Test: {BASE_URL}/voice/test-websocket-integration")
    print(f"   LLM Routing Test: {BASE_URL}/voice/test-llm-routing")
    
    # Run with optimized settings for RunPod
    uvicorn.run(
        app,
        host=host,
        port=port,
        reload=False,
        log_level="info",
        workers=1,
        loop="asyncio",
        access_log=True,
        timeout_keep_alive=30,
        timeout_graceful_shutdown=10
    )